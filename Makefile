# Paths 
SRC_TOKENS = lexical
BUILD_PATH = build
BIN_PATH = $(BUILD_PATH)

# extensions
SRC_EXT = x
TOKEN_EXT = hs

# compiler 
LC = ghc

# tokenizer
TOKENIZER = alex

# executable
BIN_NAME = out.exe

# Find all source files in the source directory, sorted by
# most recently modified
SOURCES = $(shell find $(SRC_TOKENS) -name '*.$(SRC_EXT)' | sort -k 1nr | cut -f2-)

all: tokenizer generate clean

# execute the alex in all archive .x
.PHONY: tokenizer
tokenizer: $(SOURCES)
	@echo "reading tokens..."
	alex $(SOURCES)

# get the .hs generated by alex
TOKENS = $(shell find $(SRC_TOKENS) -name '*.$(TOKEN_EXT)' | sort -k 1nr | cut -f2-)

# generate a executable
.PHONY: generate
generate: $(TOKENS)
	@echo "compiling..."
	ghc -o $(BIN_NAME) $(TOKENS)

.PHONY: clean
clean: $(SRC_TOKENS) 
	@echo "\nCleaning up..."
	@rm -rf $(SRC_TOKENS)/*.o
	@rm -rf $(SRC_TOKENS)/*.hi
	@rm -rf $(SRC_TOKENS)/*.hs
